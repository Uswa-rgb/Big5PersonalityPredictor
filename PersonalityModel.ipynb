{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PersonalityModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma1jndDj2veE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import graphviz as gviz\n",
        "import math\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jApCPwL3eh-",
        "colab_type": "text"
      },
      "source": [
        "global Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIZzzmxD3Foi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "negatively_keyed = ['EXT2', 'EXT4', 'EXT6', 'EXT8', 'EXT10',\n",
        "                    'EST2', 'EST4', 'AGR1', 'AGR3', 'AGR5',\n",
        "                    'AGR7', 'CSN2', 'CSN4', 'CSN6', 'CSN8', \n",
        "                    'OPN2', 'OPN4', 'OPN6']\n",
        "\n",
        "NAME = \"big5-model-{}\".format(int(time.time()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3ZkWMTr3pLs",
        "colab_type": "text"
      },
      "source": [
        "Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsaskQ6H3M1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadDataset():\n",
        "    df = pd.read_csv(\"/content/drive/My Drive/AI Project/data-final.csv\", sep='\\t')\n",
        "    df = df.dropna()\n",
        "    df\n",
        "    df1 = df.iloc[:,0:50]\n",
        "    df1.loc[:, negatively_keyed] = 6 - df.loc[:, negatively_keyed]\n",
        "    df1 = df1.div(5)  # normalizing dataext = df1.iloc[:,0:10]\n",
        "    ext = df1.iloc[:,0:10]\n",
        "    extlabel = ext.mean(axis = 1)\n",
        "    est = df1.iloc[:,10:20]\n",
        "    estlabel = est.mean(axis = 1)\n",
        "    agr = df1.iloc[:,20:30]\n",
        "    agrlabel = agr.mean(axis = 1)\n",
        "    csn = df1.iloc[:,30:40]\n",
        "    csnlabel = csn.mean(axis = 1)\n",
        "    opn = df1.iloc[:,40:50]\n",
        "    opnlabel = opn.mean(axis = 1)    \n",
        "\n",
        "    #print(extlabel,estlabel,agrlabel,csnlabel,opnlabel)  \n",
        "    labels = pd.DataFrame({\"AEXT\":extlabel,\"AEST\":estlabel,\"AAGR\":agrlabel,\"ACSN\":csnlabel,\"AOPN\":opnlabel})\n",
        "    \n",
        "    # shuffle\n",
        "    idx = np.random.permutation(df1.index)\n",
        "    df1 = df1.reindex(idx)\n",
        "    labels=labels.reindex(idx)\n",
        "    trainSetX = df1.iloc[0:int(0.95*df1.shape[0]),:]\n",
        "    testSetX = df1.iloc[int(0.95*df1.shape[0]):,:]\n",
        "    trainSetY = labels.iloc[0:int(0.95*labels.shape[0]),:]\n",
        "    testSetY = labels.iloc[int(0.95*labels.shape[0]):,:]\n",
        "    return trainSetX.to_numpy(), trainSetY.to_numpy(), testSetX.to_numpy(), testSetY.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dVLXxUi3w-g",
        "colab_type": "text"
      },
      "source": [
        "NN model with two layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgVepkNu3v3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def twoLayerNN():\n",
        "    Epochs = 10\n",
        "    batchSize = 32\n",
        "    X_train, Y_train, X_Test, Y_test = loadDataset()\n",
        "   \n",
        "    model = Sequential(name = NAME)\n",
        "    model.add(Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dense(5,  activation=\"sigmoid\"))\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "    model.compile(optimizer= tf.keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
        "    history = model.fit(X_train, Y_train, validation_split=0.2, epochs=Epochs, batch_size= batchSize, verbose=1)\n",
        "    model.evaluate(X_Test,Y_test,batch_size=1000, verbose=1)\n",
        "    model.save(\"two_bigfiveperonality_{}.model\".format(time.time()))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(history.history['categorical_accuracy'])\n",
        "    plt.plot(history.history['val_categorical_accuracy'])\n",
        "    plt.title('2 layer nn accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.savefig(\"two_layer_accuracy_plot_{}.png\".format(time.time()))\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.clf()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('2 layer nn loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.savefig(\"two_loss_plot_{}.png\".format(time.time()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx_6X1BD38PL",
        "colab_type": "text"
      },
      "source": [
        "NN model with one layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCNIRlm-35kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def oneLayerNN():\n",
        "    Epochs = 100\n",
        "    batchSize = 256\n",
        "    X_train, Y_train, X_Test, Y_test = loadDataset()\n",
        "   \n",
        "    model = Sequential(name = NAME)\n",
        "    model.add(Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(5,  activation=\"sigmoid\"))\n",
        "    model.summary()\n",
        "    tf.keras.utils.plot_model(model, to_file='oneLayerNN.png', show_shapes=True)\n",
        "\n",
        "\n",
        "    model.compile(optimizer= tf.keras.optimizers.SGD(lr=0.001), loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
        "    history = model.fit(X_train, Y_train, validation_split=0.2, epochs=Epochs, batch_size= batchSize, verbose=1)\n",
        "    model.evaluate(X_Test,Y_test,batch_size=1000, verbose=1)\n",
        "    model.save(\"oneLayer_bigfiveperonality_{}.model\".format(time.time()))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(history.history['categorical_accuracy'])\n",
        "    plt.plot(history.history['val_categorical_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.savefig(\"oneLayer_accuracy_plot_{}.png\".format(time.time()))\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.clf()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.savefig(\"oneLayer_loss_plot_{}.png\".format(time.time()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4izri7SS4IXj",
        "colab_type": "text"
      },
      "source": [
        "Model using one layer regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIrRRGbC4EVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regressionNN():\n",
        "    Epochs = 10\n",
        "    batchSize = 64\n",
        "    X_train, Y_train, X_test, Y_test = loadDataset()\n",
        "\n",
        "    regression = Sequential(name=\"Big5-regression\")\n",
        "    regression.add(Dense(64, activation ='relu', input_shape=(X_train.shape[1],)))\n",
        "    regression.add(Dense(5))\n",
        "    regression.summary()\n",
        "    tf.keras.utils.plot_model(regression, to_file=\"regression.png\", show_shapes=True)\n",
        "\n",
        "    regression.compile(optimizer= tf.keras.optimizers.Adam(lr=0.001), loss='mse', metrics=['accuracy'])\n",
        "    history = regression.fit(X_train, Y_train, validation_split=0.2, epochs=Epochs, batch_size= batchSize, verbose=1)\n",
        "    regression.evaluate(X_test, Y_test, batch_size=128, verbose=1)\n",
        "    regression.save(\"regression_{}\".format(time.time()))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('regression accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.savefig(\"regression_accuracy_plot_{}.png\".format(time.time()))\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plot.clf()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('regression loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.savefig(\"regression_loss_plot_{}.png\".format(time.time()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ4SNeJfqC5x",
        "colab_type": "text"
      },
      "source": [
        "Decision Tree Scorer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNA_dLpxqJXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ScoreTree(ActualLabels, PredictedLabels):\n",
        "\n",
        "  #            Multi Tree Code\n",
        "\n",
        "  Score = 0\n",
        "  for x in range(0,ActualLabels.shape[0]-1):\n",
        "    if(math.isclose(ActualLabels[x],PredictedLabels[x])):\n",
        "      Score += 1\n",
        "\n",
        "  return Score\n",
        "  \n",
        "  #            Single Tree Code\n",
        "\n",
        "  # ScorePerTrait = np.zeros(5)\n",
        "  # TotalScore: double = 0\n",
        "\n",
        "  # for x in range(0,ActualLabels.shape[0]):\n",
        "  #   for y in range(0,ActualLabels.shape[1]):\n",
        "  #       if(math.isclose(ActualLabels[x][y],PredictedLabels[x][y])):\n",
        "  #         ScorePerTrait[y] += 1\n",
        "  #         TotalScore += 1\n",
        "\n",
        "  # AccuracyPercentage = ((TotalScore/(ActualLabels.shape[0]*ActualLabels.shape[1]))*100)\n",
        "  # for x in range(0,ScorePerTrait.shape[0]):\n",
        "  #   ScorePerTrait[x] = ((ScorePerTrait[x]/ActualLabels.shape[0]) * 100)\n",
        "\n",
        "  # return AccuracyPercentage, ScorePerTrait"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fb_WTDxFl2m",
        "colab_type": "text"
      },
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0jxzACl4Yjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DecisionTree(Depth):\n",
        "  TrainingData, TrainingLabels, TestData, TestLabels = loadDataset() \n",
        "  \n",
        "  TrainingDataExt, TrainingDataEst, TrainingDataAgr, TrainingDataCsn, TrainingDataOpn = np.hsplit(TrainingData,5)\n",
        "  TrainingLabelsExt, TrainingLabelsEst, TrainingLabelsAgr, TrainingLabelsCsn, TrainingLabelsOpn = np.hsplit(TrainingLabels,5)\n",
        "  TestDataExt, TestDataEst, TestDataAgr, TestDataCsn, TestDataOpn = np.hsplit(TestData,5)\n",
        "  TestLabelsExt, TestLabelsEst, TestLabelsAgr, TestLabelsCsn, TestLabelsOpn = np.hsplit(TestLabels,5)\n",
        "  \n",
        "  \n",
        "  \n",
        "  #Extraversion\n",
        "  RegressorExt = tree.DecisionTreeRegressor(max_depth = Depth)\n",
        "  RegressorExt = RegressorExt.fit(TrainingDataExt, TrainingLabelsExt)\n",
        "  #print(\"Extraversion Tree Depth = \" + str(RegressorExt.get_depth()))\n",
        "\n",
        "  PredictionExt = RegressorExt.predict(TestDataExt)\n",
        "  ExtScore = ScoreTree(TestLabelsExt, PredictionExt)\n",
        "  #print(ExtScore)\n",
        "  ExtPercent = ((ExtScore/TestLabelsExt.shape[0]) *100)\n",
        "  #print(ExtPercent)\n",
        "\n",
        "  #Neuroticism\n",
        "  RegressorEst = tree.DecisionTreeRegressor(max_depth = Depth)\n",
        "  RegressorEst = RegressorEst.fit(TrainingDataEst, TrainingLabelsEst)\n",
        "  #print(\"Neuroticism Tree Depth = \" + str(RegressorEst.get_depth()))\n",
        "\n",
        "  PredictionEst = RegressorEst.predict(TestDataEst)\n",
        "  EstScore = ScoreTree(TestLabelsEst, PredictionEst)\n",
        "  #print(EstScore)\n",
        "  EstPercent = ((EstScore/TestLabelsEst.shape[0]) *100)\n",
        "  #print(EstPercent)\n",
        "  \n",
        "\n",
        "  #Agreeableness\n",
        "  RegressorAgr = tree.DecisionTreeRegressor(max_depth = Depth)\n",
        "  RegressorAgr = RegressorAgr.fit(TrainingDataAgr, TrainingLabelsAgr)\n",
        "  #print(\"Agreeableness Tree Depth = \" + str(RegressorAgr.get_depth()))\n",
        "\n",
        "  PredictionAgr = RegressorAgr.predict(TestDataAgr)\n",
        "  AgrScore = ScoreTree(TestLabelsAgr, PredictionAgr)\n",
        "  #print(AgrScore)\n",
        "  AgrPercent = ((AgrScore/TestLabelsAgr.shape[0]) *100)\n",
        "  #print(AgrPercent)\n",
        "\n",
        "  #Conscientiosness\n",
        "  RegressorCsn = tree.DecisionTreeRegressor(max_depth = Depth)\n",
        "  RegressorCsn = RegressorCsn.fit(TrainingDataCsn, TrainingLabelsCsn)\n",
        "  #print(\"Csn Tree Depth = \" + str(RegressorCsn.get_depth()))\n",
        "\n",
        "  PredictionCsn = RegressorCsn.predict(TestDataCsn)\n",
        "  CsnScore = ScoreTree(TestLabelsCsn, PredictionCsn)\n",
        "  #print(CsnScore)\n",
        "  CsnPercent = ((CsnScore/TestLabelsCsn.shape[0]) *100)\n",
        "  #print(CsnPercent)\n",
        "\n",
        "\n",
        "  #Openness\n",
        "  RegressorOpn = tree.DecisionTreeRegressor(max_depth = Depth)\n",
        "  RegressorOpn = RegressorOpn.fit(TrainingDataOpn, TrainingLabelsOpn)\n",
        "  #print(\"Openness Tree Depth = \" + str(RegressorOpn.get_depth()))\n",
        "\n",
        "  PredictionOpn = RegressorOpn.predict(TestDataOpn)\n",
        "  OpnScore = ScoreTree(TestLabelsOpn, PredictionOpn)\n",
        "  #print(OpnScore)\n",
        "  OpnPercent = ((OpnScore/TestLabelsOpn.shape[0]) *100)\n",
        "  #print(OpnPercent)\n",
        "\n",
        "\n",
        "  TotalScore = ExtScore + EstScore + AgrScore + CsnScore + OpnScore\n",
        "  AccuracyPercentage = ( (TotalScore / (TestLabels.shape[0]*TestLabels.shape[1]) ) *100)\n",
        "  #print(\"Total Accuracy: \" + str(AccuracyPercentage))\n",
        "\n",
        "  # Regressor = tree.DecisionTreeRegressor(max_depth = Depth)\n",
        "  # Regressor = Regressor.fit(TrainingData, TrainingLabels)\n",
        "  # print(\"Depth = \" + str(Regressor.get_depth()))\n",
        "\n",
        "  # Predictions = Regressor.predict(TestData)\n",
        "  \n",
        "  \n",
        "  \n",
        "  AccuracyPercentagePerTrait = np.array([ExtPercent, EstPercent, AgrPercent, CsnPercent, OpnPercent])\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  # tree.plot_tree(Regressor, max_depth = 4)\n",
        "\n",
        "  # Predictions = Regressor.predict(TestData)\n",
        "  # print(TestLabels.shape)\n",
        "  # print(Predictions.shape)\n",
        "  # accuracyPercentage, accuracyPercentagePerFactor = ScoreTree(TestLabels,Predictions)\n",
        "  # print('Percentage Accuracy = ' + str(accuracyPercentage) + '%\\n')\n",
        "  # print('Percetage Accuracy Per Trait')\n",
        "  # print('Extraversion: ' + str(accuracyPercentagePerFactor[0]))\n",
        "  # print('Emotional Stability: ' + str(accuracyPercentagePerFactor[1]))\n",
        "  # print('Agreeableness: ' + str(accuracyPercentagePerFactor[2]))\n",
        "  # print('Conscientiosness: ' + str(accuracyPercentagePerFactor[3]))\n",
        "  # print('Openness: ' + str(accuracyPercentagePerFactor[4]))\n",
        "  return AccuracyPercentage, AccuracyPercentagePerTrait"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBlLU7_rtZvB",
        "colab_type": "text"
      },
      "source": [
        "Multi-Depth Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1frVRk9qtd3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DecisionTreeWrapper():\n",
        "  Accuracies = np.zeros(12)\n",
        "  AccuraciesPerTrait = np.empty((12,5), dtype=object)\n",
        "  print(AccuraciesPerTrait.shape)\n",
        "  i=0\n",
        "  for x in range(10, 32, 2):\n",
        "    Accuracies[i], Temp = DecisionTree(x)\n",
        "    AccuraciesPerTrait[i] = Temp\n",
        "    i=i+1\n",
        "\n",
        "  i=0\n",
        "  for x in range(10, 32, 2):\n",
        "    print(\"Max Depth = \" + str(x))\n",
        "    print(\"Accuracy =\" + str(Accuracies[i]))\n",
        "    print(\"Accuracies Per Trait:\")\n",
        "    print('Extraversion: ' + str(AccuraciesPerTrait[i][0]))\n",
        "    print('Emotional Stability: ' + str(AccuraciesPerTrait[i][1]))\n",
        "    print('Agreeableness: ' + str(AccuraciesPerTrait[i][2]))\n",
        "    print('Conscientiosness: ' + str(AccuraciesPerTrait[i][3]))\n",
        "    print('Openness: ' + str(AccuraciesPerTrait[i][4]) + '\\n')\n",
        "    i=i+1\n",
        "\n",
        "  # plotting accuracies for traits \n",
        "  ext,emt,agr,cons,opn=np.hsplit(AccuraciesPerTrait,5)\n",
        "  x_axis=np.arange(10, 32, 2).tolist()\n",
        "\n",
        "  plt.title(\"Accuracies per Trait\")\n",
        "  plt.xlabel(\"Depth\")\n",
        "  plt.ylabel(\"Accuracies\")\n",
        "\n",
        "  #for plotting extraversion\n",
        "  plt.plot(x_axis,ext)\n",
        "  #for Emotional Stability\n",
        "  plt.plot(x_axis,emt)\n",
        "  #for plotting agreeableness\n",
        "  plt.plot(x_axis,agr)\n",
        "  #for plotting Conscientiosness\n",
        "  plt.plot(x_axis,cons)\n",
        "  #for plotting Openness\n",
        "  plt.plot(x_axis,opn)\n",
        "\n",
        "  plt.legend([\"Extraversion\",\"Emotional Stability\",\"Agreeableness\",\"Conscientiosness\",\"Openness\"], loc='upper left')\n",
        "  plt.show\n",
        "  plt.savefig(\"accuracy_per_trait{}.png\".format(time.time()))\n",
        "\n",
        "  # plotting for total accuracy\n",
        "  plt.title(\"Total Accuracy\")\n",
        "  plt.xlabel(\"Depth\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "\n",
        "  plt.plot(x_axis,Accuracies)\n",
        "  plt.show\n",
        "  plt.savefig(\"total_accuracy{}.png\".format(time.time()))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxfIcKRRF51t",
        "colab_type": "text"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9820jYFl4P-o",
        "colab_type": "code",
        "outputId": "65c597d8-6ab0-4b02-c3b2-960ed23033d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def main():\n",
        "  #loadDataset()\n",
        "   #oneLayerNN()\n",
        "   #twoLayerNN()\n",
        "  #regressionNN()\n",
        "  DecisionTreeWrapper()\n",
        "\n",
        "#run here\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12, 5)\n",
            "Max Depth = 10\n",
            "Accuracy =0.011461771041242614\n",
            "Accuracies Per Trait:\n",
            "Extraversion: 0.0\n",
            "Emotional Stability: 0.009880837104519495\n",
            "Agreeableness: 0.013833171946327293\n",
            "Conscientiosness: 0.015809339367231192\n",
            "Openness: 0.01778550678813509\n",
            "\n",
            "Max Depth = 12\n",
            "Accuracy =0.12647471493784954\n",
            "Accuracies Per Trait:\n",
            "Extraversion: 0.11461771041242615\n",
            "Emotional Stability: 0.10868920814971444\n",
            "Agreeableness: 0.12252238009604174\n",
            "Conscientiosness: 0.06126119004802087\n",
            "Openness: 0.22528308598304447\n",
            "\n",
            "Max Depth = 14\n",
            "Accuracy =0.7888860344248365\n",
            "Accuracies Per Trait:\n",
            "Extraversion: 0.66399225342371\n",
            "Emotional Stability: 0.7252534434717309\n",
            "Agreeableness: 0.7133964389463076\n",
            "Conscientiosness: 0.5473983755903801\n",
            "Openness: 1.2943896606920537\n",
            "\n",
            "Max Depth = 16\n",
            "Accuracy =6.206351402090785\n",
            "Accuracies Per Trait:\n",
            "Extraversion: 4.049167045432089\n",
            "Emotional Stability: 4.859395688002688\n",
            "Agreeableness: 6.936347647372686\n",
            "Conscientiosness: 3.7922652807145822\n",
            "Openness: 11.394581348931881\n",
            "\n",
            "Max Depth = 18\n",
            "Accuracy =21.194000355710134\n",
            "Accuracies Per Trait:\n",
            "Extraversion: 19.919767602711303\n",
            "Emotional Stability: 17.311226607118154\n",
            "Agreeableness: 22.895875738592576\n",
            "Conscientiosness: 15.342963855897871\n",
            "Openness: 30.500167974230774\n",
            "\n",
            "Max Depth = 20\n",
            "Accuracy =46.666798411161395\n",
            "Accuracies Per Trait:\n",
            "Extraversion: 46.8806197261032\n",
            "Emotional Stability: 41.57065786613442\n",
            "Agreeableness: 49.78953816967373\n",
            "Conscientiosness: 36.96618777542833\n",
            "Openness: 58.12698851846728\n",
            "\n",
            "Max Depth = 22\n",
            "Accuracy =68.2686797225461\n",
            "Accuracies Per Trait:\n",
            "Extraversion: 68.57300950536529\n",
            "Emotional Stability: 64.79852973143885\n",
            "Agreeableness: 70.57881943758275\n",
            "Conscientiosness: 60.32251052309152\n",
            "Openness: 77.07052941525207\n",
            "\n",
            "Max Depth = 24\n",
            "Accuracy =73.84107661601091\n",
            "Accuracies Per Trait:\n",
            "Extraversion: 72.77038910736518\n",
            "Emotional Stability: 71.58271248740193\n",
            "Agreeableness: 75.58642768215323\n",
            "Conscientiosness: 68.49791514337095\n",
            "Openness: 80.76793865976325\n",
            "\n",
            "Max Depth = 26\n",
            "Accuracy =74.23512439973915\n",
            "Accuracies Per Trait:\n",
            "Extraversion: 72.99567219334821\n",
            "Emotional Stability: 72.23682390372113\n",
            "Agreeableness: 75.83937711202893\n",
            "Conscientiosness: 69.24095409363082\n",
            "Openness: 80.86279469596664\n",
            "\n",
            "Max Depth = 28\n",
            "Accuracy =74.36397051558208\n",
            "Accuracies Per Trait:\n",
            "Extraversion: 73.37312017074086\n",
            "Emotional Stability: 72.41863130644428\n",
            "Agreeableness: 76.13184989032271\n",
            "Conscientiosness: 69.19945457779183\n",
            "Openness: 80.69679663261071\n",
            "\n",
            "Max Depth = 30\n",
            "Accuracy =74.37740845404423\n",
            "Accuracies Per Trait:\n",
            "Extraversion: 73.32964448748098\n",
            "Emotional Stability: 72.64786672726913\n",
            "Agreeableness: 76.23856293105152\n",
            "Conscientiosness: 68.97812382665059\n",
            "Openness: 80.6928442977689\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-68ab6fae56f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#run here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-68ab6fae56f3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0;31m#twoLayerNN()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#regressionNN()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mDecisionTreeWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#run here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-e59e7515327f>\u001b[0m in \u001b[0;36mDecisionTreeWrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m#for plotting extraversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0;31m#for Emotional Stability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (11,) and (12, 1)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlDaqr4md-6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}